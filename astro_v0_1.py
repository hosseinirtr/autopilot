# -*- coding: utf-8 -*-
"""astro_v0.1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SFBCbp-eMi4H933lKYtM6FiJ4i_RX_Gl
"""


import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import keras
from keras.models import Sequential
from keras.optimizers import Adam
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from imgaug import augmenters as iaa
import cv2
import pandas as pd
import random
import ntpath


datadir = 'astro'
columns = ['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed']
data1 = pd.read_csv(os.path.join('astro/driving_log/driving_log_git.csv'), names=columns)
data2 = pd.read_csv(os.path.join('astro/driving_log/driving_log_my_sim.csv'), names=columns)
data = pd.concat([data1, data2],ignore_index=True)

pd.set_option('display.max_colwidth',-1)
data.head()

def path_leaf(path):
  head,tail = ntpath.split(path)
  return f'astro/IMG/{tail}'

data['center'] = data['center'].apply(path_leaf)
data['right'] = data['right'].apply(path_leaf)
data['left'] = data['left'].apply(path_leaf)


sample_per_bin = 200
num_bins = 25
hist,bins = np.histogram(data['steering'],num_bins)
center = (bins[:-1]+bins[1:])*0.5
plt.bar(center, hist, width = 0.05)
plt.plot((np.min(data['steering']),np.max(data['steering'])),(sample_per_bin,sample_per_bin))

print('totla data: ', len(data))
remove_list = []

for j in range(num_bins):
  list_ = []
  for i in range(len(data['steering'])):
    if bins[j] <= data['steering'][i] <= bins[j+1]:
      list_.append(i)
  list_ = shuffle(list_)
  list_ = list_[sample_per_bin:]
  remove_list.extend(list_)

print('removed: ' , len(remove_list))

data.drop(data.index[remove_list], inplace=True)

print('remaing: ', len(data))

hist,_ = np.histogram(data['steering'],(num_bins))

plt.bar(center,hist,width=0.5)
plt.plot((np.min(data['steering']),
          np.max(data['steering'])),
         (sample_per_bin,sample_per_bin))

def load_img_streeng(df):
  image_paths = []
  steerings = []

  for i in range(len(data)):
    indexed_data = data.iloc[i]
    center , left , right = indexed_data[0],indexed_data[1],indexed_data[2]
    image_paths.append(center.strip())
    steerings.append(float(indexed_data[3]))
  image_paths = np.asarray(image_paths)
  steerings = np.asarray(steerings)
  return image_paths , steerings

# print(data.iloc[10])

image_paths , steerings = load_img_streeng(data)
print(len(image_paths),len(steerings))

# Test and train data

X_train ,X_valid, y_train, y_valid =  train_test_split(
    image_paths,
    steerings ,
    test_size = 0.2,
    random_state = 6)
print(len(X_train) ,len(X_valid), len(y_train), len(y_valid))

fig,axes = plt.subplots(1,2,figsize=(12,4))

axes[0].hist(y_train,bins = num_bins,width=0.05,color="blue")
axes[0].set_title('Training Set')

axes[1].hist(y_valid,bins = num_bins,width=0.05,color="red")
axes[1].set_title('Validation Set')

def img_preprocess(img):
  img = mpimg.imread(img)
  img = img[60:135, :,:]
  img = cv2.cvtColor(img,cv2.COLOR_RGB2YUV)
  img = cv2.GaussianBlur(img,(3,3),0)
  img = cv2.resize(img, (200,66))
  img = img/255
  return img

image = image_paths[1000]


original_img = mpimg.imread(image)
preprocessed_img = img_preprocess(image)

fig,axs = plt.subplots(1,2,figsize=(15,10))
fig.tight_layout()
axs[0].imshow(original_img)
axs[0].set_title('original image')

axs[1].imshow(preprocessed_img)
axs[1].set_title('preprocessed image')

X_train = np.array(list(map(img_preprocess,X_train)))
X_valid = np.array(list(map(img_preprocess,X_valid)))

plt.imshow(X_train[random.randint(0,len(X_train)-1)])
plt.axis('off')
print(X_train.shape)

def nvidia_model():
  model = Sequential()
  model.add(Conv2D(24,(5,5),strides = (2,2), input_shape=(66,200,3),activation = 'elu'))
  model.add(Conv2D(36,(5,5),strides = (2,2),activation = 'elu'))
  model.add(Conv2D(48,(5,5),strides = (2,2),activation = 'elu'))
  model.add(Conv2D(64,(3,3),activation = 'elu'))
  model.add(Conv2D(64,(3,3),activation = 'elu'))
  model.add(Dropout(0.5))
  model.add(Flatten())
  model.add(Dense(100, activation='elu'))
  model.add(Dropout(0.5))
  model.add(Dense(50, activation='elu'))
  model.add(Dropout(0.5))
  model.add(Dense(10, activation='elu'))
  model.add(Dropout(0.5))
  model.add(Dense(1))
  model.compile(Adam(lr=0.001),loss="mse")
  return model

model = nvidia_model()
print(model.summary())

print(len(X_valid))

history = model.fit(X_train,y_train, epochs=30, validation_data=(X_valid,y_valid),batch_size=100,verbose=1 , shuffle=1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(('Training', 'Validat'))
plt.title('Loss')
plt.xlabel('Epoch')

model.save('model.h5')

from google.colab import files
files.download('model.h5')
